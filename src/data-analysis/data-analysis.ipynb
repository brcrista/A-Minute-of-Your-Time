{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Minute of Your Time: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import dateutil\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scripts import text_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to the location of your data file\n",
    "data_file_location = '../../data/pull-requests.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the JSON file\n",
    "def ensure_camel(s):\n",
    "    \"\"\"\n",
    "    Convert a string to camel case.\n",
    "    Some of the JSON properties in the response from the Azure DevOps API are not camel-cased.\n",
    "    \"\"\"\n",
    "    allowed_names = ['_links']\n",
    "    return s if text_helpers.iscamel(s) or s in allowed_names else text_helpers.camel(s)\n",
    "\n",
    "with open(data_file_location, 'r', encoding='utf-8') as pull_requests_json_file:\n",
    "    pull_requests_raw = json.load(pull_requests_json_file, object_hook=lambda d: text_helpers.remap_keys(ensure_camel, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame of pull requests\n",
    "def get_data_from_pull_request(pull_request):\n",
    "    \"\"\"\n",
    "    Extract the information we want to process from a pull request API object.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        pull_request['pullRequestId'],\n",
    "        pull_request['createdBy']['displayName'],\n",
    "        dateutil.parser.parse(pull_request['creationDate']),\n",
    "        dateutil.parser.parse(pull_request['closedDate']),\n",
    "        len(pull_request['reviewers'])\n",
    "    ]\n",
    "\n",
    "pull_requests = pd.DataFrame(\n",
    "    [get_data_from_pull_request(pr) for pr in pull_requests_raw],\n",
    "    columns=['id', 'author', 'created_time', 'merged_time', 'num_reviewers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for wall-clock time to complete\n",
    "pull_requests['ttl'] = pull_requests['merged_time'] - pull_requests['created_time']\n",
    "pull_requests['ttl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_requests.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pull_requests.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What range of data do we have?\n",
    "first_merge = pull_requests['merged_time'].min()\n",
    "last_merge = pull_requests['merged_time'].max()\n",
    "print(f\"Data goes from {first_merge.date()} to {last_merge.date()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown of all PR completion times\n",
    "pull_requests['ttl'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown of PRs completed in under an hour\n",
    "pull_requests['ttl'][lambda x: x < datetime.timedelta(hours=1)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown of PRs completed in over 5 days\n",
    "pull_requests['ttl'][lambda x: x > datetime.timedelta(days=5)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown by author\n",
    "pull_requests.groupby('author')['ttl'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who completed the most PRs?\n",
    "ttl_by_author = pull_requests.groupby('author')['ttl']\n",
    "ttl_by_author.size().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the CIX team ...\n",
    "cix_team = ['Brian Cristante', 'Chris Sidiü¶â', 'David Staheli', 'Hank Weber', 'Jason Prickett', 'Josh Gross', 'Kellie Jos üêâ', 'Leah Antkiewicz', 'Lucas Killgore', 'Madhuri Gummalla', 'PJ Quirk', 'Yang Cao (VSNC)']\n",
    "cix_pull_requests = pull_requests.join(pd.DataFrame({'author': cix_team}).set_index('author'), on='author', how='inner')\n",
    "cix_pull_requests.groupby('author')['ttl'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of completion time\n",
    "plt.figure()\n",
    "pull_requests['ttl'].apply(lambda x: x.total_seconds()).plot.hist(bins=100)\n",
    "\n",
    "plt.xlabel('Time to complete PR (seconds)')\n",
    "plt.xlim([0, datetime.timedelta(days=10).total_seconds()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
